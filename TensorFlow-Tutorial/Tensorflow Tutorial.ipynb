{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial\n",
    "\n",
    "Machine learning frameworks like TensorFlow, PaddlePaddle, Torch, Caffe, Keras, and many others can speed up your machine learning development significantly. Programing frameworks can not only shorten your coding time, but sometimes also perform optimizations that speed up your code.  In this tutorial, I will cover the following topics with TensorFlow: \n",
    "\n",
    "- Initialize variables\n",
    "- Start your own session\n",
    "- Train algorithms \n",
    "- Implement a Neural Network\n",
    "\n",
    "\n",
    "\n",
    "## 1 - Exploring the Tensorflow Library\n",
    "- 1.1 Variables, placeholders and sessions.\n",
    "- 1.2 Linear function\n",
    "- 1.3 Computing the sigmoid\n",
    "- 1.4 Computing the Cost\n",
    "- 1.5 Using One Hot encodings\n",
    "- 1.6 Initialize with zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this cell because It solves the following error that makes the kernel die\n",
    "#OMP: Error #15: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized.\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Variables, placeholders and sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with an example, where we compute the loss of one training example. \n",
    "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
    "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # Create a variable for the loss\n",
    "init = tf.global_variables_initializer()         # When init is run later (session.run(init)),\n",
    "                                                 # the loss variable will be initialized and ready to be computed\n",
    "with tf.Session() as session:                    # Create a session and print the output\n",
    "    session.run(init)                            # Initializes the variables\n",
    "    print(session.run(loss))                     # Prints the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing and running programs in TensorFlow has the following steps:\n",
    "\n",
    "1. Create Tensors (variables) that are not yet executed/evaluated. \n",
    "2. Write operations between those Tensors.\n",
    "3. Initialize your Tensors. \n",
    "4. Create a Session. \n",
    "5. Run the Session. \n",
    "\n",
    "Therefore, when we created a variable for the loss, we simply defined the loss as a function of other quantities, but did not evaluate its value. To evaluate it, we had to run `init=tf.global_variables_initializer()`. That initialized the loss variable, and in the last line we were finally able to evaluate the value of `loss` and print its value.\n",
    "\n",
    "Now let us look at an easy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we do not see 20! We get a tensor saying that the result is a tensor that does not have the shape attribute, and is of type \"int32\". All we did was put in the 'computation graph', but you have not run this computation yet. In order to actually multiply the two numbers, we will have to create a session and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize: **initialize variables, create a session and run the operations inside the session**. \n",
    "\n",
    "Next, we'll also have to know about placeholders. A placeholder is an object whose value you can specify only later. \n",
    "To specify values for a placeholder, we can pass in values by using a \"feed dictionary\" (`feed_dict` variable). Below, we created a placeholder for x. This allows us to pass in a number later when we run the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Change the value of x in the feed_dict\n",
    "\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A placeholder is simply a variable that we will assign data to only later, when running the session. We say that you **feed data** to these placeholders when running the session. \n",
    "\n",
    "Here's what's happening: When we specify the operations needed for a computation, we are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values we will specify only later. Finally, when we run the session, we are telling TensorFlow to execute the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Linear function\n",
    "\n",
    "Lets start this programming exercise by computing the following equation: $Y = WX + b$, where $W, X$, and $b$ are drawn from a random normal distribution. W is of shape (4, 3), X is (3,1) and b is (4,1). \n",
    "\n",
    "Helpful functions: \n",
    "- tf.matmul(..., ...) to do a matrix multiplication\n",
    "- tf.add(..., ...) to do an addition\n",
    "- np.random.randn(...) to initialize randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implements a linear function: \n",
    "            Initializes W to be a random tensor of shape (4,3)\n",
    "            Initializes X to be a random tensor of shape (3,1)\n",
    "            Initializes b to be a random tensor of shape (4,1)\n",
    "    Returns: \n",
    "    result -- runs the session for Y = WX + b \n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.constant(np.random.randn(4,3), name = \"W\")\n",
    "    b = tf.constant(np.random.randn(4,1), name = \"b\")\n",
    "    Y = tf.add(tf.matmul(W,X),b)\n",
    "    # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    # close the session \n",
    "    sess.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Computing the sigmoid \n",
    "Tensorflow offers a variety of commonly used neural network functions like `tf.sigmoid` and `tf.softmax`. For this exercise let's compute the sigmoid function of an input. Let's use a placeholder variable `x`. When running the session, we should use the feed dictionary to pass in the input `z`. \n",
    "\n",
    "Let's follow these steps to do this:\n",
    "- create a placeholder `x` with `tf.placeholder(tf.float32, name = \"...\")` function, \n",
    "- define the operations needed to compute the sigmoid using `tf.sigmoid`, \n",
    "- run the session with `sess.run(..., feed_dict = {x: z})`. \n",
    "\n",
    "There are two typical ways to create and use sessions in tensorflow: \n",
    "\n",
    "**Method 1:**\n",
    "```python\n",
    "sess = tf.Session()\n",
    "# Run the variables initialization (if needed), run the operations\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() # Close the session\n",
    "```\n",
    "**Method 2:**\n",
    "```python\n",
    "with tf.Session() as sess: \n",
    "    # run the variables initialization (if needed), run the operations\n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "    # This takes care of closing the session for you :)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "    Returns: \n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32, name = \"x\")\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "    # Create a session, and run it.\n",
    "    # You should use a feed_dict to pass z's value to x. \n",
    "    with tf.Session() as sess:\n",
    "        # Run session and call the output \"result\"\n",
    "        result = sess.run(sigmoid, feed_dict={x: z})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.9999938\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 -  Computing the Cost\n",
    "\n",
    "We can use the built-in function to compute the cost of our neural network. So instead of needing to write code to compute this as a function of $a^{[2](i)}$ and $y^{(i)}$ for i=1...m: \n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small$$\n",
    "\n",
    "we can do it in one line of code in tensorflow!\n",
    "\n",
    "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "    labels -- vector of labels y (1 or 0) \n",
    "    Note: What we've been calling \"z\" and \"y\" in this class are respectively called \"logits\" and \"labels\" \n",
    "    in the TensorFlow documentation. So logits will feed into z, and labels into y. \n",
    "    Returns:\n",
    "    cost -- runs the session of the cost (formula (2))\n",
    "    \"\"\"\n",
    "    # Create the placeholders for \"logits\" (z) and \"labels\" (y) (approx. 2 lines)\n",
    "    z = tf.placeholder(tf.float32, name = \"z\")\n",
    "    y = tf.placeholder(tf.float32, name = \"y\")\n",
    "    # Use the loss function (approx. 1 line)\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z,  labels = y)\n",
    "    # Create a session (approx. 1 line). See method 1 above.\n",
    "    sess = tf.Session()\n",
    "    # Run the session (approx. 1 line).\n",
    "    cost = sess.run(cost, feed_dict = {z:logits, y:labels})\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/andicuko/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "cost = [1.0053872  1.0366409  0.41385433 0.39956614]\n"
     ]
    }
   ],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Using One Hot encodings\n",
    "\n",
    "Many times in deep learning we will have a y vector with numbers ranging from 0 to C-1, where C is the number of classes. If C is for example 4, then you might have the following y vector which you will need to convert as follows:\n",
    "\n",
    "<img src=\"images/onehot.png\" style=\"width:600px;height:150px;\">\n",
    "\n",
    "In tensorflow, you can use one line of code: \n",
    "\n",
    "- tf.one_hot(labels, depth, axis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1.               \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C,name=\"C\")\n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    return one_hot\n",
    "\n",
    "# with numpy it would be like this\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 - Initialize with zeros and ones\n",
    "\n",
    "To initialize a vector of zeros and ones we will be calling `tf.zeros()` and `tf.ones()`. These functions take in a shape and return an array of dimension shape full of zeros and ones respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(shape):\n",
    "    \"\"\"\n",
    "    Creates an array of zeros of dimension shape\n",
    "    Arguments:\n",
    "    shape -- shape of the array you want to create\n",
    "    Returns: \n",
    "    zeros -- array containing only zeros\n",
    "    \"\"\"  \n",
    "    # Create \"zeros\" tensor using tf.zeros(...). (approx. 1 line)\n",
    "    zeros = tf.zeros(shape)  \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session() \n",
    "    # Run the session to compute 'ones' (approx. 1 line)\n",
    "    zeros = sess.run(zeros)\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    return zeros\n",
    "\n",
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Creates an array of ones of dimension shape\n",
    "    Arguments:\n",
    "    shape -- shape of the array you want to create\n",
    "    Returns: \n",
    "    ones -- array containing only ones\n",
    "    \"\"\"\n",
    "    # Create \"ones\" tensor using tf.ones(...). (approx. 1 line)\n",
    "    ones = tf.ones(shape)\n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    # Run the session to compute 'ones' (approx. 1 line)\n",
    "    ones = sess.run(ones)\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    return ones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [1. 1. 1.]\n",
      "zeros = [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))\n",
    "print (\"zeros = \" + str(zeros([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Building a neural network in tensorflow\n",
    "\n",
    "In this part we will build a neural network using tensorflow. There are two parts to implement a tensorflow model:\n",
    "\n",
    "- Create the computation graph\n",
    "- Run the graph\n",
    "\n",
    "### 2.0 - Problem statement: SIGNS Dataset\n",
    "\n",
    "In this problem we build a model capable of recognizing digits from pictures of hands representing numbers.\n",
    "\n",
    "- **Training set**: 1080 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (180 pictures per number).\n",
    "- **Test set**: 120 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (20 pictures per number).\n",
    "\n",
    "This is a subset of the SIGNS dataset. The complete dataset contains many more signs.\n",
    "\n",
    "Here are examples for each number, and how an explanation of how we represent the labels. These are the original pictures, before we lowered the image resolutoion to 64 by 64 pixels.\n",
    "<img src=\"images/hands.png\" style=\"width:800px;height:350px;\"><caption><center> <u><font color='purple'> **Figure 1**</u><font color='purple'>: SIGNS dataset <br> <font color='black'> </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper funtion to load the data set\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "# helper funtion that creates random mini batches. We need this for training the model.\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = int(math.floor(m/mini_batch_size)) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the index below and run the cell to visualize some examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 249\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the data for the model we need to flatten the image dataset, then normalize it by dividing by 255. On top of that, we will convert each label to a one-hot vector as shown in Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (12288, 1080)\n",
      "Y_train shape: (6, 1080)\n",
      "X_test shape: (12288, 120)\n",
      "Y_test shape: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "# Normalize image vectors\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that 12288 comes from $64 \\times 64 \\times 3$. Each image is square, 64 by 64 pixels, and 3 is for the RGB colors. Please make sure all these shapes make sense to you before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal** is to build an algorithm capable of recognizing a sign with high accuracy. To do so, we are going to build a tensorflow model that is almost the same as one we have previously built in numpy for cat recognition (but now using a softmax output). It is a great occasion to compare your numpy implementation to the tensorflow one. \n",
    "\n",
    "**The model** is *LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX*. The SIGMOID output layer has been converted to a SOFTMAX. A SOFTMAX layer generalizes SIGMOID to when there are more than two classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Create placeholders\n",
    "\n",
    "Let's start with creating placeholders for `X` and `Y`. This will allow us to later pass our training data in when we run your session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(shape=[n_x, None], dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[n_y, None], dtype=tf.float32)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Initializing the parameters\n",
    "\n",
    "The second task is to initialize the parameters in tensorflow. We are going use Xavier Initialization for weights and Zero Initialization for biases. The shapes are given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "    W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [6,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [6,1], initializer = tf.zeros_initializer())\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Forward propagation in tensorflow \n",
    "\n",
    "We will now implement the forward propagation module in tensorflow. The function will take in a dictionary of parameters and it will complete the forward pass. We will be using the following tensorflow functions: \n",
    "\n",
    "- `tf.add(...,...)` to do an addition\n",
    "- `tf.matmul(...,...)` to do a matrix multiplication\n",
    "- `tf.nn.relu(...)` to apply the ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']   \n",
    "                                                                     # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                  # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                 # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 # Z3 = np.dot(W3,Z2) + b3\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Compute cost\n",
    " \n",
    "It is important to know that the \"`logits`\" and \"`labels`\" inputs of `tf.nn.softmax_cross_entropy_with_logits` are expected to be of shape (number of examples, num_classes). We have thus transposed Z3 and Y.\n",
    "Besides, `tf.reduce_mean` basically does the summation over the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Backward propagation & parameter updates\n",
    "\n",
    "In tensorflow, all the backpropagation and the parameters update is taken care of in 1 line of code. It is very easy to incorporate this line in the model.\n",
    "\n",
    "After computing the cost function we will create an \"`optimizer`\" object. we have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate. The code for doing so is: `optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)`\n",
    "\n",
    "To make the optimization you would do:\n",
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "```\n",
    "\n",
    "This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs.\n",
    "\n",
    "**Note** When coding, we often use `_` as a \"throwaway\" variable to store values that we won't need to use later. Here, `_` takes on the evaluated value of `optimizer`, which we don't need (and `c` takes the value of the `cost` variable). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - Building the model\n",
    "\n",
    "Now, let's bring it all together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ops.reset_default_graph()  \n",
    "#tf.set_random_seed(1)      \n",
    "#seed = 3                   \n",
    "#(n_x, m) = X_train.shape   \n",
    "#n_y = Y_train.shape[0]     \n",
    "#costs = [] \n",
    "#n_x, m, n_y\n",
    "#X, Y = create_placeholders(n_x,n_y)\n",
    "#parameters = initialize_parameters()\n",
    "#Z3 = forward_propagation(X, parameters)\n",
    "#cost = compute_cost(Z3, Y)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(cost)\n",
    "#init = tf.global_variables_initializer()\n",
    "#sess = tf.Session()\n",
    "#result = sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epoch in range(200):\n",
    "#    print(epoch)\n",
    "#    epoch_cost = 0. # Defines a cost related to an epoch\n",
    "#    num_minibatches = int(m / 32) # number of minibatches of size minibatch_size in the train set\n",
    "#    seed = seed + 1\n",
    "#    minibatches = random_mini_batches(X_train, Y_train, 32, seed)\n",
    "#\n",
    "#    for minibatch in minibatches:\n",
    "#        # Select a minibatch\n",
    "#        (minibatch_X, minibatch_Y) = minibatch\n",
    "#        print(\"probably here stops\")\n",
    "#        # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "#        # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "#        _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "#        epoch_cost += minibatch_cost / num_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0. # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It takes about 5 minutes to train this model. The Cost after epoch 100 should be around 1.016458. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.855702\n",
      "Cost after epoch 100: 1.017255\n",
      "Cost after epoch 200: 0.733184\n",
      "Cost after epoch 300: 0.573071\n",
      "Cost after epoch 400: 0.468573\n",
      "Cost after epoch 500: 0.381228\n",
      "Cost after epoch 600: 0.313815\n",
      "Cost after epoch 700: 0.253708\n",
      "Cost after epoch 800: 0.203900\n",
      "Cost after epoch 900: 0.166453\n",
      "Cost after epoch 1000: 0.146636\n",
      "Cost after epoch 1100: 0.107279\n",
      "Cost after epoch 1200: 0.086699\n",
      "Cost after epoch 1300: 0.059341\n",
      "Cost after epoch 1400: 0.052289\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "('Train Accuracy:', 0.9990741)\n",
      "('Test Accuracy:', 0.725)\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm can recognize a sign representing a figure between 0 and 5 with 71.7% accuracy. The model seems big enough to fit the training set well. However, given the difference between train and test accuracy, we could try to add L2 or dropout regularization to reduce overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the follwing code to try it on your own image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "# we need the following helping functions\n",
    "def predict(X, parameters):\n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    x = tf.placeholder(\"float\", [12288, 1])\n",
    "    z3 = forward_propagation(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})  \n",
    "    return prediction\n",
    "\n",
    "my_image = \"your_image.jpg\"\n",
    "\n",
    "# preprocess the image to fit the algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "my_image_prediction = predict(my_image, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**To remember**:\n",
    "- The two main object classes in tensorflow are Tensors and Operators. \n",
    "- Following steps when coding in tensorflow:\n",
    "    - Create a graph containing Tensors (Variables, Placeholders ...) and Operations (tf.matmul, tf.add, ...)\n",
    "    - Create a session\n",
    "    - Initialize the session\n",
    "    - Run the session to execute the graph\n",
    "- We can execute the graph multiple times as you've seen in model()\n",
    "- The backpropagation and optimization is automatically done when running the session on the \"optimizer\" object."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
